# -*- coding: utf-8 -*-
"""CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KKJeSD82MB2bF_8VVHqeJGsr7FkjQmKO
"""

!pip install tensorflow_addons

import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
import PIL
import PIL.Image
import pathlib
from google.colab import drive
drive.mount('/content/drive')

#data_dir = "/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/EstadoMaduracionChirimoya"
data_dir = '/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/EstadoMaduracionChirimoya'
data_dir = pathlib.Path(data_dir)
image_count = len(list(data_dir.glob('**/*.jpg')))
maduros = len(list(data_dir.glob('Maduro/*')))
inmaduros = len(list(data_dir.glob('Inmaduro/*')))
print(maduros)
print(inmaduros)

inmaduros = list(data_dir.glob('Inmaduro/*'))
PIL.Image.open(str(inmaduros[0]))

img_height = 180
img_width = 180
batch_size = 32

train_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.30,
  subset="training",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)

class_names = train_ds.class_names
print(class_names)

val_ds = tf.keras.utils.image_dataset_from_directory(
  data_dir,
  validation_split=0.30,
  subset="validation",
  seed=123,
  image_size=(img_height, img_width),
  batch_size=batch_size)
train_ds

train_ds = train_ds.map(lambda x,y: (x/255, y))
val_ds = val_ds.map(lambda x,y: (x/255, y))

scaled_iterator = train_ds.as_numpy_iterator()
batch = scaled_iterator.next()
fig, ax = plt.subplots(ncols=4, figsize = (20,20))
for idx, img in enumerate(batch[0][:4]):
  ax[idx].imshow(img)
  ax[idx].title.set_text(batch[1][idx])
  # 0: inmaduro, 1: maduro

import datetime
import pytz
log_dir = "logs/cnn2_mas_neurona/" + datetime.datetime.now(pytz.timezone('America/Lima')).strftime("%Y%m%d-%H:%M:%S")
print(log_dir)


all_timezones = pytz.all_timezones

print(all_timezones)

"""AUMENTO DE DATOS"""

data_augmentation = tf.keras.Sequential([
  tf.keras.layers.RandomFlip("horizontal_and_vertical"),
  tf.keras.layers.RandomRotation(0.2),
  tf.keras.layers.RandomZoom(0.3),
])

image, label = next(iter(train_ds))
_ = plt.imshow(image[0].numpy())
_ = plt.title(class_names[label[0]])
print(image.shape)

plt.figure(figsize=(10, 10))
for i in range(9):
  augmented_image = data_augmentation(image)
  ax = plt.subplot(3, 3, i + 1)
  plt.imshow(augmented_image[0].numpy())
  plt.axis("off")

"""MODELO FINAL"""

modelCNN2_AD = tf.keras.Sequential([
    #Añadiendo datos aumentados
    data_augmentation,

    # Agregar el primer par de capas convolucionales y agrupación
    tf.keras.layers.Conv2D(16, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    # Agregar el segundo par de capas convolucionales y agrupación
    tf.keras.layers.Conv2D(32, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    # Agregar el tercer par de capas convolucionales y agrupación
    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    # Agregar el cuarto par de capas convolucionales y agrupación
    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),
    tf.keras.layers.MaxPooling2D(),

    # Aplanar los mapas de características en un vector unidimensional
    tf.keras.layers.Flatten(),

    # Agregar una capa densa de 250 neuronas
    tf.keras.layers.Dense(250, activation='relu'),

    # Agregar una capa densa de clasificación
    tf.keras.layers.Dense(1, activation='sigmoid')
])

modelCNN2_AD.compile(
  optimizer='adam',
  loss=tf.losses.BinaryCrossentropy(from_logits=False),
  metrics=['accuracy'])


import datetime
import pytz
from sklearn.utils import class_weight
y_train = np.concatenate([np.zeros(202), np.ones(346)])

class_weights = class_weight.compute_class_weight(class_weight='balanced',
                                                  classes=np.unique(y_train),
                                                  y=y_train)
class_weights = dict(enumerate(class_weights))

print("Pesos de clase:", class_weights)


log_dir_drive = "/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/"

log_dir = log_dir_drive + "logs4/cnn2_con_ad/" + datetime.datetime.now(pytz.timezone('America/Lima')).strftime("%Y-%m-%d %H:%M:%S")
tensorBoardCNN2_AD = tf.keras.callbacks.TensorBoard(log_dir=log_dir)
modelCNN2_AD.fit(
  train_ds,
  validation_data=val_ds,
  epochs=100,
  class_weight=class_weights,
  callbacks = [tensorBoardCNN2_AD]
)
print("Carpeta: " + log_dir)

modelCNN2_AD.summary()

# Guarda el modelo en el formato nativo de Keras
modelCNN2_AD.save('/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/estado-madurez-cnn-ad.keras')

import cv2
img = cv2.imread('/content/drive/MyDrive/chirimoya2.jpg')
print(img)
resize = tf.image.resize(img, (180,180))
#plt.imshow(rezise.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.imshow(resize.numpy().astype(int))
plt.show()

np.expand_dims(resize,0).shape

from tensorflow.keras.models import load_model

# Cargar el modelo desde el formato .keras (suponiendo que ya tienes el archivo .keras)
model = load_model('/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/estado-madurez-cnn-ad.keras')

#modelCNN2_AD
yhat = model.predict(np.expand_dims(resize/255, 0))
print(yhat)

if yhat > 0.5:

    print(f'Predicted class is maduro')
else:
    print(f'Predicted class is inmaduro')

!pip install tensorflowjs

!mkdir hola

!tensorflowjs_converter --input_format keras "/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/estado-madurez-cnn-ad.keras" "/content/hola"



test_ds = tf.keras.utils.image_dataset_from_directory('/content/drive/MyDrive/InteligenciaArtificial/Trabajo_Final_IA/DataTest', image_size=(img_height, img_width))
test_ds = test_ds.map(lambda x,y: (x/255, y))

from sklearn.metrics import classification_report
from sklearn.utils import class_weight

y = np.concatenate([y for x, y in test_ds], axis=0)
x = np.concatenate([x for x, y in test_ds], axis=0)
x_test = x
y_test = y
y_pred = model.predict(x_test, batch_size=64, verbose=1)
y_pred_bool = np.round(y_pred)

print(classification_report(y_test, y_pred_bool))

from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score

images, labels = tuple(zip(*test_ds))
y = np.concatenate([y for x, y in test_ds], axis=0)
x = np.concatenate([x for x, y in test_ds], axis=0)
# preduction
X_test = x
y_test = y
y_pred = model.predict(X_test)
y_pred = np.round(y_pred)
# compute the confusion matrix
cm = confusion_matrix(y_test,y_pred)

#Plot the confusion matrix.
sns.heatmap(cm,
            annot=True,
            fmt='g',
            xticklabels=['inmaduro', 'maduro'],
            yticklabels=['inmaduro', 'maduro'])
plt.ylabel('Prediction',fontsize=13)
plt.xlabel('Actual',fontsize=13)
plt.title('Confusion Matrix',fontsize=17)
plt.show()


# Finding precision and recall
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy   :", accuracy)
precision = precision_score(y_test, y_pred)
print("Precision :", precision)
recall = recall_score(y_test, y_pred)
print("Recall    :", recall)
F1_score = f1_score(y_test, y_pred)
print("F1-score  :", F1_score)